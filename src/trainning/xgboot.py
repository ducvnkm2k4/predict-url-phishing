import xgboost as xgb
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import pandas as pd
from joblib import dump

def train_xgboost(data_train, data_test, is_find_best_model=False):
    # TÃ¡ch Ä‘áº·c trÆ°ng (X) vÃ  nhÃ£n (y)
    X_train = data_train.drop(columns=['label'])
    y_train = data_train['label']
    X_test = data_test.drop(columns=['label'])
    y_test = data_test['label']

    if is_find_best_model:
        print("ğŸš€ Äang tÃ¬m tham sá»‘ tá»‘t nháº¥t cho XGBoost vÆ¡Ìi 7 nhÃ¢n...")

        param_grid = {
            'n_estimators': [100, 200],
            'max_depth': [6, 10],
            'learning_rate': [0.01, 0.05, 0.1],
            'subsample': [0.8, 1.0],
            'colsample_bytree': [0.8, 1.0]
        }

        base_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)

        grid_search = GridSearchCV(
            estimator=base_model,
            param_grid=param_grid,
            cv=3,
            n_jobs=7,
            verbose=2,
            scoring='accuracy'
        )

        grid_search.fit(X_train, y_train)
        best_model = grid_search.best_estimator_

        print(f"âœ… Tham sá»‘ tá»‘t nháº¥t: {grid_search.best_params_}")
        print(f"âœ… Äá»™ chÃ­nh xÃ¡c CV cao nháº¥t: {grid_search.best_score_:.4f}")
    else:
        print("ğŸš€ Äang huáº¥n luyá»‡n XGBoost vá»›i tham sá»‘ máº·c Ä‘á»‹nh...")
        best_model = xgb.XGBClassifier(
            n_estimators=200,
            learning_rate=0.05,
            # max_depth=10,
            # subsample=0.8,
            # use_label_encoder=False,
            # eval_metric='logloss',
            random_state=42,
        )
        best_model.fit(X_train, y_train)

    # Dá»± Ä‘oÃ¡n
    y_pred = best_model.predict(X_test)

    # ÄÃ¡nh giÃ¡
    accuracy = accuracy_score(y_test, y_pred)
    conf_matrix = confusion_matrix(y_test, y_pred)
    class_report = classification_report(y_test, y_pred)

    # LÆ°u mÃ´ hÃ¬nh
    dump(best_model, "model/model/xgboost.pkl")


    # In káº¿t quáº£
    print(f"âœ… Äá»™ chÃ­nh xÃ¡c trÃªn táº­p test: {accuracy:.4f}")
    print("\nğŸ“Œ Ma tráº­n nháº§m láº«n:\n", conf_matrix)
    print("\nğŸ“Š BÃ¡o cÃ¡o phÃ¢n loáº¡i:\n", class_report)
    with open("model/report/metrics_report_xgboot.txt", "w", encoding="utf-8") as f:

        f.write("------------------xgboot-----------------------")
        f.write(f"âœ… Äá»™ chÃ­nh xÃ¡c trÃªn táº­p test: {accuracy:.4f}\n\n")
        f.write("ğŸ“Œ Ma tráº­n nháº§m láº«n:\n")
        f.write(str(conf_matrix) + "\n\n")
        f.write("ğŸ“Š BÃ¡o cÃ¡o phÃ¢n loáº¡i:\n")
        f.write(class_report)

if __name__ == "__main__":
    # Load dá»¯ liá»‡u
    data_train = pd.read_csv('data_processing/feature/data_train.csv')
    data_test = pd.read_csv('data_processing/feature/data_test.csv')
    # Gá»i hÃ m Ä‘á»ƒ huáº¥n luyá»‡n
    train_xgboost(data_train, data_test)

